{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CBU5201_miniproject"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaGn4ICrfqXZ"
      },
      "source": [
        "# 1 Author\n",
        "\n",
        "**Student Name**:  Han Jiarui\n",
        "\n",
        "**Student ID**:  221167054\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o38VQkcdKd6k"
      },
      "source": [
        "# 2 Problem formulation\n",
        "\n",
        "Distinguishing between true and deceptive stories is a challenging problem because the way deception is expressed is subjective and subtle. Different individuals may convey deceptive content in different ways, and capturing these nuances and reflecting them in a machine learning model is a highly intriguing challenge. What makes this even more appealing to me is that this challenge allows me to apply what I’ve learned, using my knowledge of machine learning in a practical context to better understand its concepts through application. Moreover, the detection of deceptive content has significant real-world applications, such as identifying false information in media, verifying the authenticity of interviews or podcasts, and improving automated systems for truth verification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPTSuaB9L2jU"
      },
      "source": [
        "# 3 Methodology\n",
        "\n",
        "In my code, I used feature extraction and machine learning classification methods based on audio data. Below is a detailed explanation of the methodology:\n",
        "\n",
        "### 1. Training Task\n",
        "The goal is to differentiate between two types of stories from audio data: True Story and Deceptive Story, which is a binary classification problem.\n",
        "- **Preprocessing**: Convert the text labels ('True Story' and 'Deceptive Story') into numbers (1 and 0), making it easier for machine learning models to process.\n",
        "- **Input Data**: Each sample's input consists of multi-dimensional features extracted from the audio file, including:\n",
        "  - **MFCC (Mel Frequency Cepstral Coefficients)**: Reflects the spectral characteristics of the audio, used to describe the main acoustic features of the sound.\n",
        "  - **Chroma**: Represents the pitch information of the audio.\n",
        "  - **Spectral Contrast**: Measures the contrast between different frequency bands.\n",
        "  - **ZCR (Zero Crossing Rate)**: Measures the frequency at which the audio signal crosses the zero value, reflecting the volatility of the signal.\n",
        "  \n",
        "  After extraction, all features (MFCC, Chroma, Spectral Contrast, Zero Crossing Rate) are averaged and concatenated, creating a feature vector for each audio file.\n",
        "- **Data Processing**:\n",
        "  - **Denoising**: Use the `noisereduce` library to reduce background noise, enhancing the quality of the audio signal.\n",
        "  - **Normalization**: Standardize the extracted features using `StandardScaler` to ensure they have a mean of 0 and a variance of 1, ensuring that feature values have similar distributions during training.\n",
        "  - Split the data into a training set (70%) and a testing set (30%) for model training and evaluation.\n",
        "- **Model Selection**: Random Forest Classifier.\n",
        "  - Random Forest is an ensemble learning method based on multiple decision trees, which is effective in handling high-dimensional data and is robust.\n",
        "\n",
        "### 2. Validation Task\n",
        "After training, the model's performance is validated on the test set. The main steps include:\n",
        "- **Data Splitting**: Use `train_test_split` to divide the dataset into training and test sets, with 70% used for training and 30% for testing.\n",
        "- **Model Evaluation Metrics**:\n",
        "  - **Accuracy**: Measures the overall correctness of predictions, i.e., the proportion of correctly predicted samples over the total number of samples.\n",
        "  - **Classification Report**: Provides a more comprehensive set of classification performance metrics, including:\n",
        "    - **Precision**: The proportion of actual positive samples among those predicted as positive.\n",
        "    - **Recall**: The proportion of correctly predicted positive samples out of the actual positive samples.\n",
        "    - **F1-Score**: The harmonic mean of precision and recall, used to balance evaluation.\n",
        "  - **Confusion Matrix**: Visualizes the model's correct predictions and misclassifications for each category.\n",
        "\n",
        "### 3. Feature Extraction Task\n",
        "To ensure that the model can accurately capture audio features, the feature extraction process is crucial for model building:\n",
        "  \n",
        "#### Feature Extraction Steps:\n",
        "1. Load the audio data using `librosa`.\n",
        "2. Perform denoising to reduce background noise interference.\n",
        "3. Extract various spectral features and calculate their means, combining them into a one-dimensional array.\n",
        "4. Repeat the above steps for each audio file to generate the feature matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3BwrtEdLDit"
      },
      "source": [
        "# 4 Implemented ML prediction pipelines\n",
        "\n",
        "In the code, I implemented a machine learning prediction pipeline using audio data as input. The goal is to classify the type of story (real or fictional). The entire pipeline is divided into the following main stages, with the data format and processing steps for each stage outlined below:\n",
        "\n",
        "1. **Input Stage**:  \n",
        "   - **Input**: Audio files and their corresponding classification labels.  \n",
        "   - **Format**: Audio files are in `.wav` format, and labels are text fields in a `.csv` file.  \n",
        "   - **Output**: Audio feature vectors and their corresponding classification labels.  \n",
        "\n",
        "2. **Feature Extraction Stage (Transformation Stage)**:  \n",
        "   - **Input**: Audio data (time-domain signals) and sampling rate.  \n",
        "   - **Processing**: Audio data is converted into feature vectors using audio feature extraction algorithms (e.g., MFCC, Chroma, Spectral Contrast, ZCR).  \n",
        "   - **Output**: NumPy arrays of feature vectors, with each audio file corresponding to one feature vector.  \n",
        "\n",
        "3. **Feature Standardization Stage**:  \n",
        "   - **Input**: Raw feature vectors generated from the feature extraction stage.  \n",
        "   - **Processing**: Features are standardized using `StandardScaler` to ensure zero mean and unit variance for the feature values.  \n",
        "   - **Output**: Standardized feature vector arrays.  \n",
        "\n",
        "4. **Model Training Stage (Model Stage)**:  \n",
        "   - **Input**: Standardized feature vectors and their corresponding classification labels.  \n",
        "   - **Processing**: The data is split into training and testing sets, and a Random Forest Classifier is trained to build the model.  \n",
        "   - **Output**: A trained classification model and the model’s predictions on the test set.  \n",
        "\n",
        "5. **Model Evaluation Stage**:  \n",
        "   - **Input**: Feature vectors of the test set and the true labels.  \n",
        "   - **Processing**: The trained model predicts the test set labels, and performance is evaluated using a classification report and accuracy score.  \n",
        "   - **Output**: Model performance metrics (e.g., accuracy).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1nDXnzYLLH6"
      },
      "source": [
        "## 4.1 Transformation stage\n",
        "\n",
        "In my code, the primary transformation stage is **feature extraction**, and the details are as follows:\n",
        "\n",
        "### 1. Feature Extraction:\n",
        "The audio data is loaded using the `librosa` library. Specifically, audio files are read through `librosa.load`, which generates the audio signal and sampling rate.  \n",
        "After loading, noise reduction is applied to the audio signal using `noisereduce.reduce_noise` to minimize the impact of background noise on feature extraction.\n",
        "\n",
        "From the denoised audio signal, the following features are extracted:\n",
        "1. **MFCC (Mel-Frequency Cepstral Coefficients)**: Extracted using `librosa.feature.mfcc`, this feature captures the spectral information of the audio. A total of 13 MFCC coefficients are extracted.  \n",
        "2. **Chroma Features**: Extracted using `librosa.feature.chroma_stft`, these represent the energy distribution across different pitches.  \n",
        "3. **Spectral Contrast**: Extracted using `librosa.feature.spectral_contrast`, this reflects the contrast in energy distribution within the spectrum.  \n",
        "4. **Zero Crossing Rate (ZCR)**: Extracted using `librosa.feature.zero_crossing_rate`, this describes the frequency of zero crossings in the signal.  \n",
        "\n",
        "Each of these features is computed and averaged using `np.mean`, forming a feature vector for each audio sample. Finally, all the features (MFCCs, Chroma, Spectral Contrast, ZCR) are concatenated into a single feature vector using `np.hstack`.\n",
        "\n",
        "The output is a two-dimensional NumPy array (`features`) containing all the audio features, along with a corresponding array of labels (`labels`).  \n",
        "Each row represents the feature vector for an audio sample, and each column corresponds to the extracted features (e.g., MFCC, Chroma, etc.).\n",
        "\n",
        "\n",
        "### 2. Reasons for Choosing This Feature Extraction Stage:\n",
        "**A. Noise Reduction**: Audio data often contains environmental noise. Noise reduction improves the signal quality, thereby enhancing the accuracy of the extracted features.\n",
        "\n",
        "**B. MFCC Features**: MFCC is one of the most commonly used features in audio analysis. It effectively captures spectral information and is especially suitable for classification tasks involving speech and music.\n",
        "\n",
        "**C. Chroma Features**: Chroma features reflect pitch distribution and are an essential dimension of audio signals, particularly effective in pitch-related classification tasks.\n",
        "\n",
        "**D. Spectral Contrast**: Spectral contrast provides additional information about the energy distribution in the spectrum, helping to distinguish audio categories with different spectral characteristics.\n",
        "\n",
        "**E. Zero Crossing Rate (ZCR)**: ZCR reflects the frequency characteristics of the audio signal and is particularly useful for coarse classification tasks involving speech or music.\n",
        "\n",
        "\n",
        "By applying these feature extraction methods and combining multi-dimensional audio features, it becomes possible to maximize the capture of useful information from the audio data. This ensures high-quality input data for subsequent classification tasks. These transformation steps not only improve data usability but also reduce noise and redundant information in the raw audio data.  \n",
        "The resulting feature matrix (`features`) and labels (`labels`) form the inputs and outputs for classification tasks, meeting the requirements for model training and prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5_kI95LuZ2"
      },
      "source": [
        "## 4.2 Model stage\n",
        "\n",
        "In my code, I chose the Random Forest Classifier as the machine learning model. Below is the description of the model and the reasons for its selection:\n",
        "\n",
        "1. **Model Description**:  \n",
        "The Random Forest Classifier is an ensemble learning method that builds multiple decision trees and performs classification or regression by voting or averaging their predictions. Its core idea is to combine the results of multiple weak learners (i.e., individual decision trees) to create a stronger model, thereby improving predictive performance and robustness.\n",
        "\n",
        "- **Input Features**: Features extracted from audio files, including MFCC, Chroma features, Spectral Contrast, and Zero-Crossing Rate, are standardized through feature engineering to serve as the model's input.  \n",
        "- **Output**: The model predicts the type of audio story (True Story or Deceptive Story), which is a binary classification problem.\n",
        "\n",
        "2. **Reasons for Choosing the Random Forest Model**:  \n",
        "\n",
        "**A. Strong Robustness**:  \n",
        "Random Forest is a non-parametric model that demonstrates high robustness to noise and missing values in data.  \n",
        "In our dataset, audio data may have some noise and uneven feature distributions. Random Forest can effectively mitigate these issues through the voting mechanism of multiple trees.\n",
        "\n",
        "**B. Stable Performance**:  \n",
        "Random Forest performs well when handling high-dimensional features and avoids overfitting issues common with single decision trees.  \n",
        "In our dataset, audio features include multiple dimensions (e.g., 13-dimensional MFCC features, 12-dimensional Chroma features, etc.), and Random Forest can effectively utilize these diverse features for classification.\n",
        "\n",
        "**C. Good Interpretability**:  \n",
        "Random Forest can provide feature importance evaluation, which helps us analyze which audio features (e.g., MFCC, Chroma, or others) contribute most to the classification task. This guides subsequent feature engineering and model optimization.\n",
        "\n",
        "**D. Easy Implementation and High Computational Efficiency**:  \n",
        "The Random Forest Classifier is very easy to implement (via Scikit-learn's `RandomForestClassifier`) and offers fast training and prediction speeds, enabling quick results.  \n",
        "In the code, the Random Forest interface provided by Sklearn is directly called, saving time on complex model tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Ensemble stage\n",
        "\n",
        "First, I chose to use the Random Forest Classifier (RandomForestClassifier), which is an ensemble learning method. Below is a detailed description of this method and the reasons for choosing it:\n",
        "\n",
        "\n",
        "### 1. The Basic Principle of Random Forest\n",
        "Random Forest is an ensemble learning method based on decision trees. It performs classification or regression tasks through the following mechanisms:\n",
        "- Constructs multiple decision trees, where each tree is built using random sampling with replacement (i.e., Bootstrap sampling) from the training data.\n",
        "- During the construction of each tree, a random subset of features is selected for splitting nodes (feature randomness).\n",
        "- Finally, the model output is obtained by voting (for classification tasks) or averaging (for regression tasks) the predictions from all decision trees.\n",
        "This approach effectively reduces the risk of overfitting associated with a single decision tree and improves the model’s generalization ability.\n",
        "\n",
        "\n",
        "### 2. Reasons for choosing random forest\n",
        "My task is to classify the story type (true/false) based on audio features. Random Forest has the following advantages for this task:\n",
        "\n",
        "**A. Strong Noise Resistance**  \n",
        "Audio data often contains noise or irrelevant features. Random Forest reduces the influence of any single feature on the final result by constructing multiple trees and randomly selecting features, thus improving the model’s robustness.\n",
        "\n",
        "**B. Handles High-Dimensional Data**  \n",
        "The audio features in this task are a combination of multiple extracted features, such as MFCC and Chroma, resulting in high dimensionality. Random Forest performs well with high-dimensional features because it trains each tree using only a random subset of features, rather than relying on all features.\n",
        "\n",
        "**C. Reduces Overfitting**  \n",
        "By aggregating the predictions of multiple decision trees, Random Forest effectively reduces the overfitting that may occur with individual decision trees, thereby improving the model’s generalization performance.\n",
        "\n",
        "**D. Easy to Implement and Interpret**  \n",
        "Random Forest is easy to use (e.g., through the sklearn library), and its feature importance analysis allows for identifying which features are most important for classification. This enhances the model’s interpretability.\n",
        "\n",
        "\n",
        "### 3. Implementation of Random Forest\n",
        "In my code, Random Forest was implemented through the following steps:\n",
        "- A Random Forest Classifier was created using the `RandomForestClassifier` class, with `random_state=42` set to ensure reproducibility of the results.\n",
        "- The Random Forest model was trained using the training data (`X_train`, `y_train`) through the `clf.fit()` method.\n",
        "- Predictions were made on the test set (`clf.predict()`), and the model's performance was evaluated using a classification report and accuracy score.\n",
        "\n",
        "\n",
        "### 4. Other Methods Used for Model Optimization and Feature Extraction\n",
        "\n",
        "**A. Standardization of Features (StandardScaler)**  \n",
        "I standardized the features to improve the model’s convergence speed. Since the value ranges of features (e.g., MFCC features and ZCR features) may vary significantly, standardization adjusts the mean of each feature to 0 and the standard deviation to 1. This ensures that all features are on the same scale and provides more stable input data for the Random Forest model, indirectly improving its performance.\n",
        "\n",
        "**B. Dataset Splitting (train_test_split)**  \n",
        "I divided the dataset into training and testing sets using `train_test_split()`. Evaluating the model's performance on an independent test set helps prevent overfitting and provides insights into the model’s generalization ability.\n",
        "\n",
        "**C. Noise Reduction**  \n",
        "I used a noise reduction method by applying the `noisereduce` library to remove noise from audio data before feature extraction. Since raw audio may contain environmental noise, which can interfere with feature extraction and degrade model performance, this step helps improve the quality of the extracted features.\n",
        "\n",
        "**D. Feature Extraction**  \n",
        "I extracted multiple audio features (MFCC, Chroma, Spectral Contrast, ZCR, etc.) using the Librosa library. Different features reflect different attributes of the audio, such as spectral characteristics, energy changes, and zero-crossing rate. Combining multiple features helps the model better understand the audio data comprehensively.\n",
        "\n",
        "\n",
        "This explanation outlines the ensemble approach (Random Forest) and additional methods used for model optimization and feature extraction, all of which contribute to the overall performance of the classification task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZQPxztuL9AW"
      },
      "source": [
        "# 5 Dataset\n",
        "\n",
        "Based on my code, the dataset construction is based on the MLEnd Deception Dataset. By extracting audio features and their corresponding labels, datasets are created for model training and evaluation. Below, I will describe the methods and details of dataset creation, explain the dataset's independence and limitations, and demonstrate step-by-step how to build, split, and visualize the datasets.\n",
        "\n",
        "### 1. Dataset Description\n",
        "\n",
        "#### A. Raw Data\n",
        "- **Audio Folder**:  \n",
        "  The folder `CBU0521DD_stories` contains all the audio files. The filenames are linked to their attributes through the file `CBU0521DD_stories_attributes.csv`.  \n",
        "- **CSV File**:  \n",
        "  Contains two main fields:  \n",
        "  - `filename`: The name of the audio file.  \n",
        "  - `Story_type`: The story type corresponding to the audio, labeled as either `True Story` (real story) or `Deceptive Story` (deceptive story).  \n",
        "\n",
        "#### B. Transformed Labels\n",
        "- The `Story_type` labels are mapped to numerical values:  \n",
        "  - `1` represents a true story.  \n",
        "  - `0` represents a deceptive story.  \n",
        "\n",
        "#### C. Extracted Features\n",
        "- The audio features are processed using `librosa` and `noisereduce`. The specific extracted features include:  \n",
        "  - **MFCCs (Mel-frequency cepstral coefficients)**: 13-dimensional MFCC features are extracted and averaged.  \n",
        "  - **Chroma Features**: Pitch features are extracted and averaged.  \n",
        "  - **Spectral Contrast Features**: Spectral contrast features are extracted and averaged.  \n",
        "  - **Zero-Crossing Rate (ZCR)**: The zero-crossing rate feature is extracted and averaged.  \n",
        "- Each audio is encoded into a feature vector, which is combined to form the model input.\n",
        "\n",
        "#### D. Dataset Limitations\n",
        "1. **Sample Size Issues**:  \n",
        "   - If the dataset is insufficient, the model may not learn effectively, resulting in limited generalization ability.  \n",
        "\n",
        "2. **Feature Information Loss**:  \n",
        "   - Reducing the dimensionality of audio features by averaging may lead to the loss of some information, which could affect the model's expressive power.  \n",
        "\n",
        "3. **Noise Reduction**:  \n",
        "   - Using `noisereduce` for noise removal may cause feature deformation, which could impact the performance of the classification model.\n",
        "\n",
        "#### 5.1 Dataset A: Extraction and Construction of Raw Data\n",
        "Preprocessing: First, convert the Story_type text labels into numbers, then read the audio and perform noise reduction to minimize background noise interference.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV column names: Index(['filename', 'Language', 'Story_type'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import noisereduce as nr\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the CSV file\n",
        "csv_url = r'D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories_attributes.csv'\n",
        "data = pd.read_csv(csv_url)\n",
        "\n",
        "# View the column names of the data\n",
        "print(\"CSV column names:\", data.columns)\n",
        "\n",
        "# Convert Story_type text labels to numbers\n",
        "story_type_mapping = {'True Story': 1, 'Deceptive Story': 0}\n",
        "data['Story_type'] = data['Story_type'].map(story_type_mapping)\n",
        "\n",
        "\n",
        "def extract_features(file_path):\n",
        "    try:\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"File not found: {file_path}\")\n",
        "            return None\n",
        "        \n",
        "        # Load the audio\n",
        "        audio, sr = librosa.load(file_path, sr=None)\n",
        "        print(f\"Successfully loaded audio: {file_path}, sample rate: {sr}\")\n",
        "\n",
        "        # Denoising\n",
        "        reduced_audio = nr.reduce_noise(y=audio, sr=sr)\n",
        "        \n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=reduced_audio, sr=sr, n_mfcc=13)\n",
        "        chroma = librosa.feature.chroma_stft(y=reduced_audio, sr=sr)\n",
        "        spectral_contrast = librosa.feature.spectral_contrast(y=reduced_audio, sr=sr)\n",
        "        zcr = librosa.feature.zero_crossing_rate(y=reduced_audio)\n",
        "        \n",
        "        # Average the features\n",
        "        mfccs_mean = np.mean(mfccs, axis=1)\n",
        "        chroma_mean = np.mean(chroma, axis=1)\n",
        "        spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
        "        zcr_mean = np.mean(zcr, axis=1)\n",
        "        \n",
        "        # Combine features\n",
        "        features = np.hstack([mfccs_mean, chroma_mean, spectral_contrast_mean, zcr_mean])\n",
        "        \n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file: {file_path}, Error: {e}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature Extraction:  \n",
        "The `extract_features` function is used to extract features from each audio file. These features include MSCCs, Chroma, Spectral Contrast, and Zero-Crossing Rate. Audio files that cannot be found or processed are logged as errors to ensure that the feature set and label set correspond correctly.\n",
        "\n",
        "Dataset Integration:  \n",
        "The extracted features are stored in the `features` list, and the labels are stored in the `labels` list. These are then converted into NumPy arrays for further processing.\n",
        "\n",
        "Normalization:  \n",
        "All features are normalized using StandardScaler to ensure that the mean of the features is 0 and the variance is 1, thereby reducing the impact of feature scale on the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00001.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00001.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00002.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00002.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00003.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00003.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00004.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00004.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00005.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00005.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00006.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00006.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00007.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00007.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00008.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00008.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00009.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00009.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00010.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00010.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00011.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00011.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00012.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00012.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00013.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00013.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00014.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00014.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00015.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00015.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00016.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00016.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00017.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00017.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00018.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00018.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00019.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00019.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00020.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00020.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00021.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00021.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00022.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00022.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00023.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00023.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00024.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00024.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00025.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00025.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00026.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00026.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00027.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00027.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00028.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00028.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00029.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00029.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00030.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00030.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00031.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00031.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00032.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00032.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00033.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00033.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00034.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00034.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00035.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00035.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00036.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00036.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00037.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00037.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00038.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00038.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00039.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00039.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00040.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00040.wav, sample rate: 24000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00041.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00041.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00042.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00042.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00043.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00043.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00044.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00044.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00045.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00045.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00046.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00046.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00047.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00047.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00048.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00048.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00049.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00049.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00050.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00050.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00051.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00051.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00052.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00052.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00053.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00053.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00054.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00054.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00055.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00055.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00056.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00056.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00057.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00057.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00058.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00058.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00059.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00059.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00060.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00060.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00061.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00061.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00062.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00062.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00063.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00063.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00064.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00064.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00065.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00065.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00066.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00066.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00067.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00067.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00068.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00068.wav, sample rate: 44100\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00069.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00069.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00070.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00070.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00071.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00071.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00072.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00072.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00073.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00073.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00074.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00074.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00075.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00075.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00076.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00076.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00077.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00077.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00078.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00078.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00079.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00079.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00080.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00080.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00081.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00081.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00082.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00082.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00083.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00083.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00084.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00084.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00085.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00085.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00086.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00086.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00087.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00087.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00088.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00088.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00089.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00089.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00090.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00090.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00091.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00091.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00092.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00092.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00093.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00093.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00094.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00094.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00095.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00095.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00096.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00096.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00097.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00097.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00098.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00098.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00099.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00099.wav, sample rate: 48000\n",
            "Processing file: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00100.wav\n",
            "Successfully loaded audio: D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories\\00100.wav, sample rate: 48000\n",
            "Number of extracted features: 100, Number of labels: 100\n"
          ]
        }
      ],
      "source": [
        "# Extract features from all audio files\n",
        "audio_folder = r'D:\\Administrator\\Desktop\\machinelearning\\CBU0521DD_stories'\n",
        "features = []\n",
        "labels = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    file_path = os.path.join(audio_folder, row['filename'])\n",
        "    print(f\"Processing file: {file_path}\")\n",
        "    feature = extract_features(file_path)\n",
        "    if feature is not None:\n",
        "        features.append(feature)\n",
        "        labels.append(row['Story_type'])\n",
        "\n",
        "# Check the number of features and labels\n",
        "print(f\"Number of extracted features: {len(features)}, Number of labels: {len(labels)}\")\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "features = np.array(features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "if len(features) == 0:\n",
        "    print(\"Error: No audio features were successfully extracted. Please check the file paths and data!\")\n",
        "else:\n",
        "    # Feature standardization\n",
        "    scaler = StandardScaler()\n",
        "    features = scaler.fit_transform(features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.2 Dataset B: Splitting into Training and Testing Sets  \n",
        "Splitting Method:  \n",
        "The `train_test_split` function is used to divide the dataset into training and testing sets, with a ratio of 70% (training set) and 30% (testing set).\n",
        "\n",
        "Independence Guarantee:  \n",
        "A random seed (`random_state=42`) is used to ensure the reproducibility of the splitting process.  \n",
        "The training and testing sets are mutually exclusive to ensure the independence of the testing set.\n",
        "\n",
        "IID Assumption:  \n",
        "It is assumed that the audio samples are independently and identically distributed (IID), and the Story_type labels are randomly distributed across the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(random_state=42)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(random_state=42)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
        "\n",
        "# Use Random Forest classifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "clf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Perform prediction evaluation on the training and testing results, plot the bar chart of MFCC feature means, visualize the PCA feature distribution, and display the confusion matrix heatmap."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.80      0.71        15\n",
            "           1       0.73      0.53      0.62        15\n",
            "\n",
            "    accuracy                           0.67        30\n",
            "   macro avg       0.68      0.67      0.66        30\n",
            "weighted avg       0.68      0.67      0.66        30\n",
            "\n",
            "Accuracy: 66.67%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Prediction and evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot: Confusion matrix heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Deceptive', 'True'], yticklabels=['Deceptive', 'True'])\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qf7GN1aeXJI"
      },
      "source": [
        "# 6 Experiments and results\n",
        "\n",
        "My experimental results and the plotted images are shown above.\n",
        "\n",
        "A. From my experimental results data, the model's accuracy is 66.67%.\n",
        "\n",
        "1. **Category 0 (Deceptive Stories)**:\n",
        "   - **Precision**: 0.63  \n",
        "     In all the samples predicted as category 0, 63% were correct. This indicates that there is some false positive in the model's prediction of deceptive stories.\n",
        "   - **Recall**: 0.80  \n",
        "     The recall for category 0 is high, meaning the model correctly detects most of the deceptive stories with a low false negative rate.\n",
        "   - **F1-score**: 0.71  \n",
        "     Combining Precision and Recall, the F1 score for category 0 is relatively high, indicating that the model performs well in classifying deceptive stories.\n",
        "\n",
        "2. **Category 1 (Real Stories)**:\n",
        "   - **Precision**: 0.73  \n",
        "     In the samples predicted as category 1, 73% were correct. The high precision indicates that there are relatively fewer false positives in the model's prediction of real stories.\n",
        "   - **Recall**: 0.53  \n",
        "     The recall for category 1 is low, at 53%, suggesting that the model fails to detect many real stories, leading to a high false negative rate.\n",
        "   - **F1-score**: 0.62  \n",
        "     The F1 score for category 1 is relatively low, indicating that the model's performance in classifying real stories is average.\n",
        "\n",
        "**Overall accuracy**: 66.67%\n",
        "\n",
        "3. **Macro Average and Weighted Average**:\n",
        "   - **Macro Avg**:  \n",
        "     Precision: 0.68, Recall: 0.67, F1-score: 0.66  \n",
        "     Macro average is the average of the metrics for both classes. The precision and recall values are close to each other, suggesting that the model is not heavily biased toward either class.\n",
        "   \n",
        "   - **Weighted Avg**:  \n",
        "     Precision: 0.68, Recall: 0.67, F1-score: 0.66  \n",
        "     The weighted average takes into account the number of samples in each class (which is the same in this case, so it aligns with the macro average). Since the class distribution is even, the macro and weighted averages are not significantly different.\n",
        "\n",
        "B. **Analysis of the Confusion Matrix**:\n",
        "\n",
        "1. **True Positive (TP)**: Top left (Deceptive-Deceptive): 12  \n",
        "   This means the model correctly identified 12 deceptive stories.\n",
        "\n",
        "2. **True Negative (TN)**: Bottom right (True-True): 8  \n",
        "   This means the model correctly identified 8 real stories.\n",
        "\n",
        "3. **False Positive (FP)**: Bottom left (True-Deceptive): 7  \n",
        "   This means the model incorrectly classified 7 real stories as deceptive.\n",
        "\n",
        "4. **False Negative (FN)**: Top right (Deceptive-True): 3  \n",
        "   This means the model incorrectly classified 3 deceptive stories as real.\n",
        "\n",
        "5. **Precision**:  \n",
        "   Precision = 12 / (7 + 12) ≈ 0.63  \n",
        "   This means that, of all the stories predicted as deceptive, 63% were correct.\n",
        "\n",
        "6. **Recall**:  \n",
        "   Recall = 12 / (3 + 12) = 0.80  \n",
        "   This means that, of all the truly deceptive stories, 80% were correctly identified.\n",
        "\n",
        "7. **Accuracy**:  \n",
        "   Accuracy = (12 + 8) / (12 + 8 + 7 + 3) ≈ 0.67\n",
        "\n",
        "8. **F1-score**:  \n",
        "   F1 = 2 * (0.63 * 0.80) / (0.63 + 0.80) ≈ 0.70\n",
        "\n",
        "**Issues noticed during testing**:\n",
        "1. The features in the data may not be sufficient to distinguish between category 0 and category 1. If the features don't well capture the difference between categories, the model, no matter how complex, will be limited.\n",
        "2. The data may contain too much noise or incorrect labeling, which could prevent the model from learning the true classification boundaries.\n",
        "3. The feature space for category 0 and category 1 might have significant overlap, making it difficult for the model to distinguish between the two classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSrJCR_cekPO"
      },
      "source": [
        "# 7 Conclusions\n",
        "\n",
        "#### Conclusion:\n",
        "Code Structure: My code is organized according to the process of reading audio data, extracting features, training, and evaluation. It utilizes common audio processing libraries such as librosa and machine learning libraries like scikit-learn.\n",
        "Functionality: The code extracts features from audio files, uses these features to train a Random Forest model, and finally generates classification reports and visual results.\n",
        "\n",
        "#### Suggestions for Improvement:\n",
        "1、Add More Audio Features:\n",
        "In addition to MFCC features, it might be helpful to try incorporating other common audio features, such as Mel-spectrograms or Zero Crossing Rate, as they could improve the model's accuracy.\n",
        "Depending on the task requirements, additional time-frequency domain features, such as Chroma or Spectral Contrast, could also be added.\n",
        "\n",
        "2、Model Tuning:\n",
        "The current model uses the default RandomForestClassifier. Hyperparameter tuning could be performed to find the optimal model configuration. For example, GridSearchCV or RandomizedSearchCV can be used for cross-validation and hyperparameter search.\n",
        "Hyperparameters such as n_estimators, max_depth, and min_samples_split significantly impact the performance of the Random Forest model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 8 References\n",
        "1、https://scikit-learn.org/stable/\n",
        "\n",
        "2、https://librosa.org/doc/latest/index.html\n",
        "\n",
        "3、https://github.com/timsainb/noisereduce\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My GitHub Address: https://github.com/HanJiaruiruirui/CBU5201_miniproject_Han-Jiarui"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
